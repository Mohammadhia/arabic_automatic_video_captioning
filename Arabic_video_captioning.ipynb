{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse generated captions from text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**: The deep learning model can generate a lot of captions, some of which are unnecessary and overlap with others. I personally deleted those that I didn't want to include (and made sure that the captions I kept didn't overlap for timeperiod). You can follow a different route if you choose. Just be aware that there is some hard-coding that takes place in the MoviePy code section (the part that overlays captions on videos) so you'll need to modify it if you have more than 2 captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"./sample_automated_captions/skiing_video_output2.txt\") #Change to the path of the text file with the generated caption output\n",
    "text_file_lines = text_file.readlines() #Extract all lines from file\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'start': 0.2, 'end': 6.5, 'sentence': 'A man is seen standing on a snowy hill holding a stick and holding a stick'}, {'start': 6.5, 'end': 8.0, 'sentence': 'A man in a black shirt is standing in front of a snow'}]\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions = text_file_lines[-1] #Select last element (last line) to get automated captions\n",
    "generated_captions = generated_captions.rstrip('\\n') #Remove trailing new line characters\n",
    "generated_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_captions = generated_captions.replace(\"]\", \"\") #Remove square brackets\n",
    "generated_captions = generated_captions.replace(\"[\", \"\")\n",
    "\n",
    "generated_captions = generated_captions.replace(\"}, \", \"};\") #Replace so that we can use ';' as a delimiter to split the string\n",
    "generated_captions_list = generated_captions.split(\";\") #Split string by ';' delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"{'start': 0.2, 'end': 6.5, 'sentence': 'A man is seen standing on a snowy hill holding a stick and holding a stick'}\",\n",
       " \"{'start': 6.5, 'end': 8.0, 'sentence': 'A man in a black shirt is standing in front of a snow'}\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_captions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_parsed_captions_list = [] #Will hold strings converted to dictionaries\n",
    "\n",
    "for item in generated_captions_list:\n",
    "    english_parsed_captions_list.append(eval(item)) #Append dictionary version of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0.2,\n",
       "  'end': 6.5,\n",
       "  'sentence': 'A man is seen standing on a snowy hill holding a stick and holding a stick'},\n",
       " {'start': 6.5,\n",
       "  'end': 8.0,\n",
       "  'sentence': 'A man in a black shirt is standing in front of a snow'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_parsed_captions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Arabic Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator \n",
    "  \n",
    "translator = google_translator() #Import google translate api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "arabic_parsed_captions_list = [] #Will hold Arabic captions\n",
    "\n",
    "for li in english_parsed_captions_list: #Make a copy of english captions (Copy the individual dictionaries in the list)\n",
    "    d2 = li.copy()\n",
    "    arabic_parsed_captions_list.append(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arabic_parsed_captions_list = english_parsed_captions_list.copy() #Make a copy of english captions\n",
    "\n",
    "for i in range(len(english_parsed_captions_list)): #Translate the text from english to Arabic\n",
    "    arabic_parsed_captions_list[i]['sentence'] = translator.translate(english_parsed_captions_list[i]['sentence'], lang_tgt='ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0.2,\n",
       "  'end': 6.5,\n",
       "  'sentence': 'شوهد رجل يقف على تل ثلجي يحمل عصا ويمسك بعصا '},\n",
       " {'start': 6.5, 'end': 8.0, 'sentence': 'يقف رجل يرتدي قميصًا أسود أمام ثلج '}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_parsed_captions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0.2,\n",
       "  'end': 6.5,\n",
       "  'sentence': 'A man is seen standing on a snowy hill holding a stick and holding a stick'},\n",
       " {'start': 6.5,\n",
       "  'end': 8.0,\n",
       "  'sentence': 'A man in a black shirt is standing in front of a snow'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_parsed_captions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin MoviePy Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1920, 1080]\n",
      "1920 1080\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "my_video = VideoFileClip(\"./sample_videos/skiing_video.mp4\", audio=True) #Replace with path to mp4 file you're using\n",
    "\n",
    "w,h = moviesize = my_video.size\n",
    "print(moviesize)\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to maintain aspect ratio if original video is in portrait mode\n",
    "if my_video.rotation == 90:\n",
    "    my_video = my_video.resize(my_video.size[::-1])\n",
    "    my_video.rotation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n",
      "1080 1920\n"
     ]
    }
   ],
   "source": [
    "w,h = moviesize = my_video.size #Check to see if aspect ratio is corrected (if original video was in portrait mode)\n",
    "\n",
    "print(moviesize)\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to mirror Arabic text (needed so that the Arabic captions in video aren't backwards)\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "def formatArabicSentences(sentences):\n",
    "   formatedSentences = arabic_reshaper.reshape(sentences)\n",
    "   return get_display(formatedSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(arabic_parsed_captions_list)): #Translate the text from english to Arabic\n",
    "    text_to_be_reveresed = arabic_parsed_captions_list[i]['sentence']\n",
    "    arabic_parsed_captions_list[i]['sentence'] = formatArabicSentences(text_to_be_reveresed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 0.2,\n",
       "  'end': 6.5,\n",
       "  'sentence': ' ﺎﺼﻌﺑ ﻚﺴﻤﻳﻭ ﺎﺼﻋ ﻞﻤﺤﻳ ﻲﺠﻠﺛ ﻞﺗ ﻰﻠﻋ ﻒﻘﻳ ﻞﺟﺭ ﺪﻫﻮﺷ'},\n",
       " {'start': 6.5, 'end': 8.0, 'sentence': ' ﺞﻠﺛ ﻡﺎﻣﺃ ﺩﻮﺳﺃ ﺎﺼﻴﻤﻗ ﻱﺪﺗﺮﻳ ﻞﺟﺭ ﻒﻘﻳ'}]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_parsed_captions_list #Sanity check to see if reversal worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic captioning for first part of clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**: You'll need to download a compatible Arabic font (ttf file) if Imagemagick doesn't provide one (Run TextClip.list('font') to see if the list contains an Arabic compatible font; if not, download an Arabic ttf font online; I recommend this one https://github.com/rastikerdar/sahel-font/blob/master/dist/Sahel.ttf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_clip1 = my_video.subclip(0, arabic_parsed_captions_list[0]['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a text clip. You can customize the font, color, etc.\n",
    "txt_clip1 = TextClip(arabic_parsed_captions_list[0]['sentence'], fontsize=48, bg_color = 'black', color='white', font='./Fonts/Sahel.ttf')\n",
    "\n",
    "\n",
    "# Say that you want it to appear at 2.5% width and 60% depth of screen (Modify as needed)\n",
    "duration = arabic_parsed_captions_list[0]['end'] - 0\n",
    "txt_clip1 = txt_clip1.set_pos((0.025, 0.6), relative=True).set_duration(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_captioned_clip1 = CompositeVideoClip([arabic_clip1, txt_clip1]) #Overlay text on arabic clip1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic captioning for second part of clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_clip2 = my_video.subclip(arabic_parsed_captions_list[1]['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a text clip. You can customize the font, color, etc.\n",
    "txt_clip2 = TextClip(arabic_parsed_captions_list[1]['sentence'], fontsize=60, bg_color = 'black', color='white', font='./Fonts/Sahel.ttf')\n",
    "\n",
    "\n",
    "# Say that you want it to appear at 10% width and 60% depth of screen (Modify as needed)\n",
    "duration = my_video.duration - arabic_parsed_captions_list[1]['start'] #Duration is from end of video to start of second caption\n",
    "txt_clip2 = txt_clip2.set_pos((0.1, 0.6), relative=True).set_duration(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_captioned_clip2 = CompositeVideoClip([arabic_clip2, txt_clip2]) #Overlay text on arabic clip2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Arabic captioning clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/228 [00:00<?, ?it/s, now=None]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Arabic_captioned_concatenated_skiing_video.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video Arabic_captioned_concatenated_skiing_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Arabic_captioned_concatenated_skiing_video.mp4\n"
     ]
    }
   ],
   "source": [
    "final_arabic_clip = concatenate_videoclips([arabic_captioned_clip1, arabic_captioned_clip2]) #Combine the 2 arabic captioned clips \n",
    "\n",
    "#Write final concatenated video to final mp4 file. All parameters after name of final mp4 file are to make sure audio is included in final product\n",
    "final_arabic_clip.write_videofile(\"Arabic_captioned_concatenated_skiing_video.mp4\", temp_audiofile='temp-audio.m4a', remove_temp=True, codec=\"libx264\", audio_codec=\"aac\") #Change name of mp4 as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English captioning for first part of clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_clip1 = my_video.subclip(0, english_parsed_captions_list[0]['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a text clip. You can customize the font, color, etc.\n",
    "# Needed to break text into 2 pieces in order to fit in video\n",
    "english_sentence1_part1 = ' '.join(english_parsed_captions_list[0]['sentence'].split()[:9])\n",
    "english_sentence1_part2 = ' '.join(english_parsed_captions_list[0]['sentence'].split()[9:])\n",
    "\n",
    "txt_clip1_1 = TextClip(english_sentence1_part1, fontsize=55, bg_color = 'black', color='white', font='Arial')\n",
    "txt_clip1_2 = TextClip(english_sentence1_part2, fontsize=55, bg_color = 'black', color='white', font='Arial')\n",
    "\n",
    "# Say that you want it to appear at 8% & 11% width and 60% & 63.5% depth of screen (Modify as needed)\n",
    "duration = english_parsed_captions_list[0]['end'] - 0\n",
    "txt_clip1_1 = txt_clip1_1.set_pos((0.08, 0.6), relative=True).set_duration(duration)\n",
    "txt_clip1_2 = txt_clip1_2.set_pos((0.11, 0.635), relative=True).set_duration(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_captioned_clip1 = CompositeVideoClip([english_clip1, txt_clip1_1, txt_clip1_2]) #Overlay text on english clip1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English captioning for second part of clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_clip2 = my_video.subclip(english_parsed_captions_list[1]['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a text clip. You can customize the font, color, etc.\n",
    "txt_clip2 = TextClip(english_parsed_captions_list[1]['sentence'], fontsize=45, bg_color = 'black', color='white', font='Arial')\n",
    "\n",
    "\n",
    "# Say that you want it to appear at 2.5% width and 60% depth of screen (Modify as needed)\n",
    "duration = my_video.duration - english_parsed_captions_list[1]['start'] #Duration is from end of video to start of second caption\n",
    "txt_clip2 = txt_clip2.set_pos((0.025, 0.6), relative=True).set_duration(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_captioned_clip2 = CompositeVideoClip([english_clip2, txt_clip2]) #Overlay text on english clip2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine English captioning clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/228 [00:00<?, ?it/s, now=None]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video English_captioned_concatenated_skiing_video.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video English_captioned_concatenated_skiing_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready English_captioned_concatenated_skiing_video.mp4\n"
     ]
    }
   ],
   "source": [
    "final_english_clip = concatenate_videoclips([english_captioned_clip1, english_captioned_clip2]) #Combine the 2 english captioned clips \n",
    "\n",
    "#Write final concatenated video to final mp4 file. All parameters after name of final mp4 file are to make sure audio is included in final product\n",
    "final_english_clip.write_videofile(\"English_captioned_concatenated_skiing_video.mp4\", temp_audiofile='temp-audio.m4a', remove_temp=True, codec=\"libx264\", audio_codec=\"aac\") #Change name of mp4 as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Arabic and English Captioned videos together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  19%|█▊        | 62/334 [00:00<00:00, 617.92it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Final_concatenated_skiing_video.mp4.\n",
      "MoviePy - Writing audio in temp-audio.m4a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 3/455 [00:00<00:16, 27.06it/s, now=None]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Final_concatenated_skiing_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Final_concatenated_skiing_video.mp4\n"
     ]
    }
   ],
   "source": [
    "final_concatenated_video = concatenate_videoclips([final_arabic_clip, final_english_clip]) #Combine the Arabic and English captioned clips \n",
    "\n",
    "#Write final concatenated video to final mp4 file. All parameters after name of final mp4 file are to make sure audio is included in final product\n",
    "final_concatenated_video.write_videofile(\"Final_concatenated_skiing_video.mp4\", temp_audiofile='temp-audio.m4a', remove_temp=True, codec=\"libx264\", audio_codec=\"aac\") #Change name of mp4 as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
